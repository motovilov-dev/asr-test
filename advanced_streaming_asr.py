import threading
import time
import queue
import numpy as np
import sounddevice as sd
import torch
import gigaam
import tempfile
import os
from typing import Optional, Callable, List, Dict
from collections import deque


class AdvancedStreamingASR:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –ø–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É—è GigaAM –º–æ–¥–µ–ª—å
    """
    
    def __init__(
        self,
        model_name: str = "ctc",
        sample_rate: int = 16000,
        chunk_duration: float = 2.0,
        silence_threshold: float = 0.01,
        silence_duration: float = 1.0,
        min_audio_duration: float = 0.5,
        max_audio_duration: float = 30.0,
        callback: Optional[Callable[[str], None]] = None,
        device: Optional[str] = None,
        verbose: bool = True
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ ASR
        
        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ GigaAM
            sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            chunk_duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–∞–Ω–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            silence_threshold: –ü–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω—Ü–∞ —Ä–µ—á–∏
            silence_duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–∏—à–∏–Ω—ã –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞
            min_audio_duration: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            max_audio_duration: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            callback: –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –º–æ–¥–µ–ª–∏ (cuda/cpu)
            verbose: –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
        """
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        self.silence_threshold = silence_threshold
        self.silence_duration = silence_duration
        self.min_audio_duration = min_audio_duration
        self.max_audio_duration = max_audio_duration
        self.callback = callback
        self.verbose = verbose
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        if self.verbose:
            print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ GigaAM...")
        
        self.model = gigaam.load_model(
            model_name,
            fp16_encoder=False,
            use_flash=False,
        )
        
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        if device:
            self.model = self.model.to(device)
        
        if self.verbose:
            print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {next(self.model.parameters()).device}")
        
        # –ë—É—Ñ–µ—Ä—ã –¥–ª—è –∞—É–¥–∏–æ
        self.audio_buffer = deque(maxlen=int(self.sample_rate * self.max_audio_duration))
        self.is_recording = False
        self.audio_queue = queue.Queue(maxsize=10)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—á–µ—Ä–µ–¥—å
        self.result_queue = queue.Queue()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'processed_chunks': 0,
            'total_audio_time': 0.0,
            'successful_transcriptions': 0,
            'failed_transcriptions': 0
        }
        
        # –ü–æ—Ç–æ–∫–∏
        self.processing_thread = None
        
    def _audio_callback(self, indata, frames, time, status):
        """Callback –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö"""
        if status:
            if self.verbose:
                print(f"–°—Ç–∞—Ç—É—Å –∞—É–¥–∏–æ: {status}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ float32 –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        audio_data = indata.copy().astype(np.float32)
        audio_data = audio_data.flatten()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
        self.audio_buffer.extend(audio_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–∏—à–∏–Ω—É –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        if len(self.audio_buffer) > self.sample_rate * self.silence_duration:
            recent_audio = list(self.audio_buffer)[-int(self.sample_rate * self.silence_duration):]
            if np.max(np.abs(recent_audio)) < self.silence_threshold:
                # –¢–∏—à–∏–Ω–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞
                audio_length = len(self.audio_buffer) / self.sample_rate
                
                if self.min_audio_duration <= audio_length <= self.max_audio_duration:
                    # –ö–æ–ø–∏—Ä—É–µ–º –±—É—Ñ–µ—Ä –∏ –æ—á–∏—â–∞–µ–º –µ–≥–æ
                    audio_chunk = np.array(list(self.audio_buffer), dtype=np.float32)
                    self.audio_buffer.clear()
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
                    try:
                        self.audio_queue.put_nowait(audio_chunk)
                    except queue.Full:
                        if self.verbose:
                            print("–û—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —á–∞–Ω–∫")
                elif audio_length > self.max_audio_duration:
                    # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç, –æ–±—Ä–µ–∑–∞–µ–º
                    max_samples = int(self.sample_rate * self.max_audio_duration)
                    audio_chunk = np.array(list(self.audio_buffer)[-max_samples:], dtype=np.float32)
                    self.audio_buffer.clear()
                    
                    try:
                        self.audio_queue.put_nowait(audio_chunk)
                    except queue.Full:
                        if self.verbose:
                            print("–û—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —á–∞–Ω–∫")
    
    def _process_audio(self):
        """–ü–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å"""
        while self.is_recording:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                audio_data = self.audio_queue.get(timeout=1.0)
                
                if audio_data is None:
                    break
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                audio_duration = len(audio_data) / self.sample_rate
                self.stats['processed_chunks'] += 1
                self.stats['total_audio_time'] += audio_duration
                
                if self.verbose:
                    print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∞—É–¥–∏–æ —á–∞–Ω–∫: {audio_duration:.2f}—Å")
                
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                    temp_filename = temp_file.name
                
                try:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ
                    self._save_audio(audio_data, temp_filename)
                    
                    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
                    result = self.model.transcribe(temp_filename)
                    
                    if result and result.strip():
                        if self.verbose:
                            print(f"üé§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {result}")
                        
                        if self.callback:
                            self.callback(result)
                        
                        self.result_queue.put(result)
                        self.stats['successful_transcriptions'] += 1
                    else:
                        if self.verbose:
                            print("–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è")
                        self.stats['failed_transcriptions'] += 1
                    
                except Exception as e:
                    if self.verbose:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}")
                    self.stats['failed_transcriptions'] += 1
                finally:
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    try:
                        os.unlink(temp_filename)
                    except OSError:
                        pass
                        
            except queue.Empty:
                continue
            except Exception as e:
                if self.verbose:
                    print(f"–û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
    
    def _save_audio(self, audio_data: np.ndarray, filename: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª"""
        import wave
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∞—É–¥–∏–æ
        if np.max(np.abs(audio_data)) > 1.0:
            audio_data = audio_data / np.max(np.abs(audio_data))
        
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(1)  # –ú–æ–Ω–æ
            wav_file.setsampwidth(2)  # 16-bit
            wav_file.setframerate(self.sample_rate)
            wav_file.writeframes((audio_data * 32767).astype(np.int16).tobytes())
    
    def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ"""
        if self.is_recording:
            if self.verbose:
                print("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ!")
            return
        
        self.is_recording = True
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processing_thread = threading.Thread(target=self._process_audio)
        self.processing_thread.daemon = True
        self.processing_thread.start()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        if self.verbose:
            print("üé§ –ù–∞—á–∏–Ω–∞—é –∑–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...")
            print("üí¨ –ì–æ–≤–æ—Ä–∏—Ç–µ –≤ –º–∏–∫—Ä–æ—Ñ–æ–Ω. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –±—É–¥–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
            print("‚èπÔ∏è  –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
        
        try:
            with sd.InputStream(
                callback=self._audio_callback,
                channels=1,
                samplerate=self.sample_rate,
                dtype=np.float32,
                blocksize=int(self.sample_rate * 0.1)  # 100ms –±–ª–æ–∫–∏
            ):
                while self.is_recording:
                    time.sleep(0.1)
                    
        except KeyboardInterrupt:
            if self.verbose:
                print("\n‚èπÔ∏è  –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...")
        except Exception as e:
            if self.verbose:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏: {e}")
        finally:
            self.stop()
    
    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ"""
        self.is_recording = False
        
        if self.processing_thread:
            self.processing_thread.join(timeout=2.0)
        
        if self.verbose:
            print("üõë –ü–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")
            self.print_stats()
    
    def get_results(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        results = []
        while not self.result_queue.empty():
            try:
                results.append(self.result_queue.get_nowait())
            except queue.Empty:
                break
        return results
    
    def print_stats(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã"""
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã:")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {self.stats['processed_chunks']}")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è –∞—É–¥–∏–æ: {self.stats['total_audio_time']:.2f}—Å")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–π: {self.stats['successful_transcriptions']}")
        print(f"   –ù–µ—É–¥–∞—á–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–π: {self.stats['failed_transcriptions']}")
        
        if self.stats['processed_chunks'] > 0:
            success_rate = (self.stats['successful_transcriptions'] / 
                          (self.stats['successful_transcriptions'] + self.stats['failed_transcriptions'])) * 100
            print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%")


def print_result(text: str):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —ç–º–æ–¥–∑–∏"""
    print(f"üéØ {text}")


def save_results_to_file(text: str, filename: str = "transcriptions.txt"):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª"""
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
    with open(filename, "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}] {text}\n")


if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ ASR
    streaming_asr = AdvancedStreamingASR(
        model_name="ctc",
        sample_rate=16000,
        chunk_duration=2.0,
        silence_threshold=0.01,
        silence_duration=1.0,
        min_audio_duration=0.5,
        max_audio_duration=30.0,
        callback=print_result,
        verbose=True
    )
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        streaming_asr.start()
    except KeyboardInterrupt:
        print("\nüëã –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
    finally:
        streaming_asr.stop() 