import threading
import time
import queue
import numpy as np
import sounddevice as sd
import torch
import gigaam
from typing import Optional, Callable


class StreamingASR:
    """
    –ü–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É—è GigaAM –º–æ–¥–µ–ª—å
    """
    
    def __init__(
        self,
        model_name: str = "ctc",
        sample_rate: int = 16000,
        chunk_duration: float = 2.0,
        silence_threshold: float = 0.01,
        silence_duration: float = 1.0,
        callback: Optional[Callable[[str], None]] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ ASR
        
        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ GigaAM
            sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            chunk_duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–∞–Ω–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            silence_threshold: –ü–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω—Ü–∞ —Ä–µ—á–∏
            silence_duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–∏—à–∏–Ω—ã –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞
            callback: –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        """
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        self.silence_threshold = silence_threshold
        self.silence_duration = silence_duration
        self.callback = callback
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ GigaAM...")
        self.model = gigaam.load_model(
            model_name,
            fp16_encoder=False,
            use_flash=False,
        )
        print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        
        # –ë—É—Ñ–µ—Ä—ã –¥–ª—è –∞—É–¥–∏–æ
        self.audio_buffer = []
        self.is_recording = False
        self.audio_queue = queue.Queue()
        self.result_queue = queue.Queue()
        
        # –ü–æ—Ç–æ–∫–∏
        self.recording_thread = None
        self.processing_thread = None
        
    def _audio_callback(self, indata, frames, time, status):
        """Callback –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö"""
        if status:
            print(f"–°—Ç–∞—Ç—É—Å –∞—É–¥–∏–æ: {status}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ float32 –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        audio_data = indata.copy().astype(np.float32)
        audio_data = audio_data.flatten()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
        self.audio_buffer.extend(audio_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–∏—à–∏–Ω—É
        if len(self.audio_buffer) > self.sample_rate * self.silence_duration:
            recent_audio = self.audio_buffer[-int(self.sample_rate * self.silence_duration):]
            if np.max(np.abs(recent_audio)) < self.silence_threshold:
                # –¢–∏—à–∏–Ω–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –±—É—Ñ–µ—Ä –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
                if len(self.audio_buffer) > self.sample_rate * 0.5:  # –ú–∏–Ω–∏–º—É–º 0.5 —Å–µ–∫—É–Ω–¥—ã
                    audio_chunk = np.array(self.audio_buffer, dtype=np.float32)
                    self.audio_queue.put(audio_chunk)
                    self.audio_buffer = []
    
    def _process_audio(self):
        """–ü–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å"""
        while self.is_recording:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                audio_data = self.audio_queue.get(timeout=1.0)
                
                if audio_data is None:
                    break
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                temp_file = f"temp_audio_{time.time()}.wav"
                self._save_audio(audio_data, temp_file)
                
                try:
                    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
                    result = self.model.transcribe(temp_file)
                    
                    if result and result.strip():
                        print(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {result}")
                        if self.callback:
                            self.callback(result)
                        self.result_queue.put(result)
                    
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}")
                finally:
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    import os
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                        
            except queue.Empty:
                continue
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
    
    def _save_audio(self, audio_data: np.ndarray, filename: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª"""
        import wave
        
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(1)  # –ú–æ–Ω–æ
            wav_file.setsampwidth(2)  # 16-bit
            wav_file.setframerate(self.sample_rate)
            wav_file.writeframes((audio_data * 32767).astype(np.int16).tobytes())
    
    def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ"""
        if self.is_recording:
            print("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ!")
            return
        
        self.is_recording = True
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processing_thread = threading.Thread(target=self._process_audio)
        self.processing_thread.daemon = True
        self.processing_thread.start()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        print("–ù–∞—á–∏–Ω–∞—é –∑–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...")
        print("–ì–æ–≤–æ—Ä–∏—Ç–µ –≤ –º–∏–∫—Ä–æ—Ñ–æ–Ω. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –±—É–¥–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
        
        try:
            with sd.InputStream(
                callback=self._audio_callback,
                channels=1,
                samplerate=self.sample_rate,
                dtype=np.float32,
                blocksize=int(self.sample_rate * 0.1)  # 100ms –±–ª–æ–∫–∏
            ):
                while self.is_recording:
                    time.sleep(0.1)
                    
        except KeyboardInterrupt:
            print("\n–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏: {e}")
        finally:
            self.stop()
    
    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ"""
        self.is_recording = False
        
        if self.processing_thread:
            self.processing_thread.join(timeout=2.0)
        
        print("–ü–æ—Ç–æ–∫–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")
    
    def get_results(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        results = []
        while not self.result_queue.empty():
            try:
                results.append(self.result_queue.get_nowait())
            except queue.Empty:
                break
        return results


def print_result(text: str):
    """–ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print(f"üé§ {text}")


if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ ASR
    streaming_asr = StreamingASR(
        model_name="ctc",
        sample_rate=16000,
        chunk_duration=2.0,
        silence_threshold=0.01,
        silence_duration=1.0,
        callback=print_result
    )
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        streaming_asr.start()
    except KeyboardInterrupt:
        print("\n–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
    finally:
        streaming_asr.stop() 